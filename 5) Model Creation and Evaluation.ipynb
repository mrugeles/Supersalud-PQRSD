{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrugeles\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 134.0, 'test_size': 0.1, 'impute': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AFEC_DPTO</th>\n",
       "      <th>AFEC_EDADR</th>\n",
       "      <th>AFEC_EDUC</th>\n",
       "      <th>AFEC_GENERO</th>\n",
       "      <th>AFEC_GETNICO</th>\n",
       "      <th>AFEC_MPIO</th>\n",
       "      <th>AFEC_PARENTESCO</th>\n",
       "      <th>AFEC_POBESPECIAL</th>\n",
       "      <th>AFEC_REGAFILIACION</th>\n",
       "      <th>AFEC_TIPOPER</th>\n",
       "      <th>...</th>\n",
       "      <th>AFEC_GETNICO_is_missing</th>\n",
       "      <th>AFEC_TIPOPER_is_missing</th>\n",
       "      <th>AFEC_EDADR_is_missing</th>\n",
       "      <th>PET_COD_DEPTO_is_missing</th>\n",
       "      <th>PATOLOGIA_TIPO_is_missing</th>\n",
       "      <th>AFEC_MPIO_is_missing</th>\n",
       "      <th>ENT_TIPOVIG_SNS_is_missing</th>\n",
       "      <th>AFEC_PARENTESCO_is_missing</th>\n",
       "      <th>PET_MPIO_is_missing</th>\n",
       "      <th>RIESGO_VIDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.137201</td>\n",
       "      <td>0.200671</td>\n",
       "      <td>0.117783</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.485508</td>\n",
       "      <td>0.094359</td>\n",
       "      <td>0.559616</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.648027</td>\n",
       "      <td>0.200671</td>\n",
       "      <td>0.485508</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.485508</td>\n",
       "      <td>0.121797</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.424883</td>\n",
       "      <td>0.200671</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.485508</td>\n",
       "      <td>0.434276</td>\n",
       "      <td>0.594707</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.567984</td>\n",
       "      <td>0.200671</td>\n",
       "      <td>0.117783</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.485508</td>\n",
       "      <td>0.230358</td>\n",
       "      <td>0.594707</td>\n",
       "      <td>0.485508</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.137201</td>\n",
       "      <td>0.200671</td>\n",
       "      <td>0.117783</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.485508</td>\n",
       "      <td>0.094359</td>\n",
       "      <td>0.559616</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AFEC_DPTO  AFEC_EDADR  AFEC_EDUC  AFEC_GENERO  AFEC_GETNICO  AFEC_MPIO  \\\n",
       "0  0.137201   0.200671    0.117783   0.693147     0.485508      0.094359    \n",
       "1  0.648027   0.200671    0.485508   0.405465     0.485508      0.121797    \n",
       "2  0.424883   0.200671    0.693147   0.405465     0.485508      0.434276    \n",
       "3  0.567984   0.200671    0.117783   0.405465     0.485508      0.230358    \n",
       "4  0.137201   0.200671    0.117783   0.405465     0.485508      0.094359    \n",
       "\n",
       "   AFEC_PARENTESCO  AFEC_POBESPECIAL  AFEC_REGAFILIACION  AFEC_TIPOPER  ...  \\\n",
       "0  0.559616         0.405465          0.693147            0.693147      ...   \n",
       "1  0.060625         0.405465          0.182322            0.693147      ...   \n",
       "2  0.594707         0.405465          0.182322            0.693147      ...   \n",
       "3  0.594707         0.485508          0.182322            0.693147      ...   \n",
       "4  0.559616         0.405465          0.693147            0.693147      ...   \n",
       "\n",
       "   AFEC_GETNICO_is_missing  AFEC_TIPOPER_is_missing  AFEC_EDADR_is_missing  \\\n",
       "0  0                        0                        0                       \n",
       "1  0                        0                        0                       \n",
       "2  0                        0                        0                       \n",
       "3  0                        0                        0                       \n",
       "4  0                        0                        0                       \n",
       "\n",
       "   PET_COD_DEPTO_is_missing  PATOLOGIA_TIPO_is_missing  AFEC_MPIO_is_missing  \\\n",
       "0  0                         0                          0                      \n",
       "1  0                         0                          0                      \n",
       "2  0                         0                          0                      \n",
       "3  0                         0                          0                      \n",
       "4  0                         0                          0                      \n",
       "\n",
       "   ENT_TIPOVIG_SNS_is_missing  AFEC_PARENTESCO_is_missing  \\\n",
       "0  0                           0                            \n",
       "1  0                           0                            \n",
       "2  0                           0                            \n",
       "3  0                           0                            \n",
       "4  0                           0                            \n",
       "\n",
       "   PET_MPIO_is_missing  RIESGO_VIDA  \n",
       "0  0                    0            \n",
       "1  0                    0            \n",
       "2  0                    0            \n",
       "3  0                    1            \n",
       "4  0                    0            \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display \n",
    "from sklearn.metrics import fbeta_score\n",
    "import model_utils as model_utils\n",
    "from sklearn.externals import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import json\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "\n",
    "with open('best_config.json') as json_data_file:\n",
    "    config = json.load(json_data_file)[0]\n",
    "print(config)\n",
    "seed = int(config['seed'])\n",
    "test_size = config['test_size']\n",
    "\n",
    "dataset = pd.read_csv(\"datasets/encoded_dataset.csv\")\n",
    "display(dataset.head(n = 5))\n",
    "\n",
    "labels = dataset[['RIESGO_VIDA']]\n",
    "features = dataset.drop(['RIESGO_VIDA'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_final set has 281311 samples.\n",
      "Training set has 253179 samples.\n",
      "Testing set has 28132 samples.\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the 'features' and 'labels' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = test_size, random_state = seed, stratify=labels)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"features_final set has {} samples.\".format(features.shape[0]))\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier trained: 0.738396\n",
      "BaggingClassifier trained: 0.762011\n",
      "ExtraTreesClassifier trained: 0.687141\n",
      "GradientBoostingClassifier trained: 0.780502\n",
      "RandomForestClassifier trained: 0.740881\n",
      "XGBClassifier trained: 0.782256\n",
      "LogisticRegression trained: 0.573509\n",
      "PassiveAggressiveClassifier trained: 0.022600\n",
      "RidgeClassifier trained: 0.553649\n",
      "RidgeClassifierCV trained: 0.553649\n",
      "SGDClassifier trained: 0.728199\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize the three models\n",
    "classifiers = model_utils.init_classifiers(seed)\n",
    "\n",
    "# Collect results on the learners\n",
    "dfResults = pd.DataFrame(columns=['learner', 'train_time', 'pred_time', 'f_test', 'f_train'])\n",
    "\n",
    "for clf in list(classifiers.values()):\n",
    "    clf_name = clf.__class__.__name__ \n",
    "    clf, dfResults = model_utils.train_predict(clf, 2, X_train, y_train, X_test, y_test, dfResults)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display( dfResults.sort_values(by=['f_test'], ascending = False)[['learner', 'f_test']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "clf = PassiveAggressiveClassifier(random_state = seed)\n",
    "\n",
    "clfParameters = {    \n",
    "  'fit_intercept':[True, False],\n",
    "  'max_iter':[1000, 2000],\n",
    "  'early_stopping':[True, False],\n",
    "  'warm_start':[True, False],\n",
    "  'class_weight': ['balanced', None],\n",
    "  'average': [True, False] \n",
    "}\n",
    "\n",
    "rf_classifier, default_rf_score, tuned_rf_score, cnf_rf_matrix = model_utils.tune_classifier(clf, clfParameters, X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_utils.plot_confusion_matrix(cnf_rf_matrix, classes=['Life not as risk', 'Life at risk'], normalize = True)\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"F-score on testing data: {:.4f}\".format(default_rf_score))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(tuned_rf_score))\n",
    "joblib.dump(rf_classifier, 'rf_classifier.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.random_state = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn_classifier = MLPClassifier()\n",
    "\n",
    "nnParameters = {\n",
    "  'hidden_layer_sizes':[50, 100, 200],\n",
    "  'activation' :['identity', 'logistic', 'tanh', 'relu'],\n",
    "  'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "  'batch_size': [700],\n",
    "  'early_stopping': [True]  \n",
    "}\n",
    "\n",
    "nn_classifier, default_nn_score, tuned_nn_score, matrix = model_utils.tune_classifier(nn_classifier, nnParameters,  X_train, X_test, y_train, y_test)\n",
    "\n",
    "#model_utils.plot_confusion_matrix(cnf_ada_matrix, classes=['Life not as risk', 'Life at risk'], normalize = True)\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"F-score on testing data: {:.4f}\".format(default_nn_score))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(tuned_nn_score))\n",
    "\n",
    "#joblib.dump(ada_classifier, 'ada_classifier.joblib') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "rf_classifier = GradientBoostingClassifier()\n",
    "\n",
    "rfParameters = { \n",
    "  'loss': ['deviance', 'exponential'],\n",
    "  #'learning_rate':[0.1, 0.5, 1],\n",
    "  'n_estimators':[50, 100, 200],\n",
    "  #'subsample': [0.5, 1], \n",
    "  'criterion':['friedman_mse', 'mse', 'mae'],\n",
    "  #'min_samples_split': sp_randint(2, 4),\n",
    "  #'min_samples_leaf': sp_randint(2, 4),\n",
    "  #'max_depth':sp_randint(5, 30),\n",
    "  #'max_features':['auto', 'sqrt', 'log2', None] \n",
    "}\n",
    "\n",
    "rf_classifier, default_rf_score, tuned_rf_score = model_utils.tune_classifier(rf_classifier, rfParameters, X_train, X_test, y_train, y_test)\n",
    "\n",
    "#model_utils.plot_confusion_matrix(cnf_rf_matrix, classes=['Life not as risk', 'Life at risk'], normalize = True)\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"F-score on testing data: {:.4f}\".format(default_rf_score))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(tuned_rf_score))\n",
    "#joblib.dump(rf_classifier, 'rf_classifier.joblib') )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "## Stacking with to best classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sclf_two, sclf_score = model_utils.get_stack_two(rf_classifier, ada_classifier, X_train, X_test, y_train, y_test, seed)\n",
    "\n",
    "joblib.dump(sclf_two, 'sclf_two.joblib') \n",
    "\n",
    "model_utils.model_validation('sclf_two.joblib', X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking with all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sclf_all, sclf_all_score = model_utils.get_stack_all(rf_classifier, ada_classifier, gauss_classifier, X_train, X_test, y_train, y_test, seed)\n",
    "\n",
    "joblib.dump(sclf_all, 'sclf_all.joblib') \n",
    "\n",
    "model_utils.model_validation('sclf_all.joblib', X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
